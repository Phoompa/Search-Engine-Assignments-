{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Download nltk stuff\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Set up stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "preprocessed_directory = 'preprocessed_data'\n",
    "all_words = set()\n",
    "# list of all file names\n",
    "filenames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each file in the directory\n",
    "\n",
    "for filename in os.listdir('data'):\n",
    "    #Constructs file path for a specific file in data folder\n",
    "    file_path = os.path.join('data',filename)\n",
    "    filenames.append(filename)\n",
    "    print(file_path)\n",
    "    \n",
    "    # Had errors reading certain files, so try different encodings\n",
    "    try:\n",
    "        #Use utf-8 encoding\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        #Try with a different encoding\n",
    "        with open(file_path, 'r', encoding='latin-1') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "    #Convert to lowercase\n",
    "    content_lower = content.lower()\n",
    "    #Create tokens\n",
    "    tokens = word_tokenize(content_lower)\n",
    "    #Remove stop words \n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    #Remove punctuation \n",
    "    processed_tokens = [re.sub(r'[\\W_]+', '', word) for word in tokens if word]  # Remove punctuation\n",
    "    #Remove singly occurring characters like 'm' or 'a'\n",
    "    processed_tokens = [word for word in processed_tokens if len(word) > 1]\n",
    "\n",
    "    #Add processed tokens to the set\n",
    "    all_words.update(processed_tokens)\n",
    "    processed_text = ' '.join(processed_tokens)\n",
    "\n",
    "    #Gets the file path to write the processed data\n",
    "    preprocessed_file_path = os.path.join(preprocessed_directory, filename)\n",
    "\n",
    "    #Write processed text to preprocessed_data\n",
    "    with open(preprocessed_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(processed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 44108\n",
      "Question 1 Completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total unique words: {len(all_words)}\")\n",
    "print(\"Question 1 Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional index complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize the positional index as a dictionary\n",
    "positional_index = {}\n",
    "term_count = {}\n",
    "term_total_max = {}\n",
    "\"\"\"{doc : [# of terms, term with max occ.]}\n",
    "    count all times each word appears within doc\n",
    "    temp = {word : count}\n",
    "    term_count = {doc : {word : count}}\n",
    "\"\"\"\n",
    "\n",
    "#Load all words from preprocessed files and build the positional index:\n",
    "for filename in os.listdir(preprocessed_directory):\n",
    "    file_path = os.path.join(preprocessed_directory,filename)\n",
    "    temp = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        words = content.split()\n",
    "        \n",
    "        #iterate through each word and its index:\n",
    "        for index, word in enumerate(words):\n",
    "            if word not in positional_index:\n",
    "                positional_index[word] = {}\n",
    "            if filename not in positional_index[word]:\n",
    "                positional_index[word][filename] = []\n",
    "                temp[word] = 0\n",
    "            positional_index[word][filename].append(index)\n",
    "            temp[word] += 1\n",
    "            \n",
    "        term_count[filename] = temp.copy()\n",
    "        m = max(temp, key=temp.get)\n",
    "        term_total_max[filename] = [len(words), temp[m], m]\n",
    "#position that the word occurs in is relative to the list of words and not the number of characters. So if document contains \"This is\", \"This\" is at position 0 and \"is\" at position 1\n",
    "            \n",
    "            \n",
    "# Write positional index to a file:\n",
    "with open('positional_index.txt', 'w') as file:\n",
    "    for word, documents in positional_index.items():\n",
    "        file.write(f\"{word}: \")\n",
    "        entries = []\n",
    "        for doc, positions in documents.items():\n",
    "            positions_str = ', '.join(map(str, positions))  # Convert list of positions to string\n",
    "            entries.append(f\"{doc} [{positions_str}]\")\n",
    "        document_positions = '; '.join(entries)  # Join all document entries with semicolon\n",
    "        file.write(f\"{document_positions}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(\"Positional index complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    phrase = input(\"Please enter a phrase:   \")\n",
    "    phrase = phrase.lower()\n",
    "\n",
    "    words = phrase.split()\n",
    "    if len(words) > 5:\n",
    "        print(\"Query length must be less than 5.\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "#Dictionary to store the combined document positions for the phrase.\n",
    "phrase_positions = {}\n",
    "\n",
    "\n",
    "#collect positions for each word in the phrase\n",
    "for word in words:\n",
    "    if word in positional_index:\n",
    "        for document, positions in positional_index[word].items():\n",
    "            if document not in phrase_positions:\n",
    "                phrase_positions[document] = []\n",
    "            phrase_positions[document].extend(positions)\n",
    "            \n",
    "#sorting the positions in each document\n",
    "for doc in phrase_positions:\n",
    "    phrase_positions[doc].sort()\n",
    "\n",
    "#print:\n",
    "#for doc, positions in phrase_positions.items():\n",
    "    #print(f\"{doc}: {positions}\")\n",
    "    \n",
    "results = {}\n",
    "\n",
    "# Check for sequences of consecutive numbers matching the phrase length\n",
    "for doc, positions in phrase_positions.items():\n",
    "    if len(positions) < len(words):\n",
    "        continue  # Skip if there aren't enough positions\n",
    "\n",
    "    # Search for consecutive positions\n",
    "    for i in range(len(positions) - len(words) + 1):\n",
    "        # Check if the next positions are consecutive\n",
    "        if all(positions[i + j] == positions[i] + j for j in range(len(words))):\n",
    "            if doc not in results:\n",
    "                results[doc] = []\n",
    "            results[doc].extend(positions[i:i+len(words)])  # Extend flat list\n",
    "\n",
    "# Output the results:\n",
    "for doc, pos_list in results.items():\n",
    "    print(f\"{doc}: {sorted(set(pos_list))}\")  # Remove duplicates and sort\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# TF-IDF MATRIX\n",
    "\"\"\"\n",
    "Term Frequency\n",
    "Inverted Document Frequency\n",
    "\n",
    "Matrix = columns[[row],[row],[row]] <-- way to reduce storage size?\n",
    "\n",
    "\n",
    "same dataset as Q1\n",
    "tf_dict = {'this' : {'100west.txt' : count, ...}}\n",
    "for each word in dictionary:\n",
    "    for each document in dictionary:\n",
    "        dic = {}\n",
    "        \n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "import math\n",
    "DOC_TOTAL = 249\n",
    "\n",
    "#term_count = {}\n",
    "#doc_count = {}\n",
    "idf = {}\n",
    "\n",
    "for word in positional_index:\n",
    "    #d = {}\n",
    "    #for doc in positional_index[word]:\n",
    "    #    d.update({doc : len(positional_index[word][doc])})\n",
    "        \n",
    "    #term_count.update({word : d.copy()})\n",
    "    #doc_count.update({word : len(positional_index[word])})\n",
    "    idf[word] = math.log(DOC_TOTAL / (len(positional_index[word])+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idf = {}\n",
    "#idf['is'] = math.log(DOC_TOTAL/(doc_count['is'] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "final solution:\n",
    "TF-IDF dataframe for each TF scheme (5 dataframes)\n",
    "\n",
    "need:\n",
    "total number of terms in each document: dict {doc : [# of terms, term with max occ]}\n",
    "term with most amount of occurence in each document: -------------->^^^^^\n",
    "\n",
    "create query vector => populate vector = vocab length with random values\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "matrix = pd.DataFrame(float(0), index=list(idf.keys()),columns=list(term_count.keys()))\n",
    "#matrix_rc = pd.DataFrame(float(0), index=list(idf.keys()),columns=list(term_count.keys()))\n",
    "#matrix_tf = pd.DataFrame(float(0), index=list(idf.keys()),columns=list(term_count.keys()))\n",
    "#matrix_ln = pd.DataFrame(float(0), index=list(idf.keys()),columns=list(term_count.keys()))\n",
    "#matrix_dn = pd.DataFrame(float(0), index=list(idf.keys()),columns=list(term_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_count ## {term : {doc : count}}\n",
    "term_total_max ## {doc : [length, max term count, max term]}\n",
    "idf ## {term : score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    tf_variant = input(\"Select term freq variant: bin | rc | tf | ln | dn\")\n",
    "    if tf_variant not in ['bin','rc','tf','ln','dn']:\n",
    "        print(\"Invalid variant.\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    \n",
    "for doc, values in term_count.items():\n",
    "    for term, count in values.items():\n",
    "        match tf_variant:\n",
    "            case 'bin':\n",
    "                matrix.loc[term,doc] = idf[term]\n",
    "            case 'rc':\n",
    "                matrix.loc[term,doc] = count*idf[term]\n",
    "            case 'tf':\n",
    "                matrix.loc[term,doc] = (count/(term_total_max[doc][0]))*idf[term]\n",
    "            case 'ln':\n",
    "                matrix.loc[term,doc] = math.log(1+count)*idf[term]\n",
    "            case 'dn':\n",
    "                matrix.loc[term,doc] = 0.5 + (0.5* (count/term_total_max[doc][1]))*idf[term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = np.random.rand(44108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100west.txt</th>\n",
       "      <th>13chil.txt</th>\n",
       "      <th>3gables.txt</th>\n",
       "      <th>3lpigs.txt</th>\n",
       "      <th>3student.txt</th>\n",
       "      <th>3wishes.txt</th>\n",
       "      <th>4moons.txt</th>\n",
       "      <th>5orange.txt</th>\n",
       "      <th>6ablemen.txt</th>\n",
       "      <th>6napolen.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>vgilante.txt</th>\n",
       "      <th>weaver.txt</th>\n",
       "      <th>weeprncs.txt</th>\n",
       "      <th>wisteria.txt</th>\n",
       "      <th>wlgirl.txt</th>\n",
       "      <th>wolf7kid.txt</th>\n",
       "      <th>wolfcran.txt</th>\n",
       "      <th>wolflamb.txt</th>\n",
       "      <th>yukon.txt</th>\n",
       "      <th>zombies.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "      <td>0.092503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.146815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shareware</th>\n",
       "      <td>4.131159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <td>2.521721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.521721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project</th>\n",
       "      <td>2.684240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.684240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priveledge</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.824306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freshest</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.824306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wellmaintained</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.824306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentenial</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.824306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caryns</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.824306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44108 rows Ã— 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                100west.txt  13chil.txt  3gables.txt  3lpigs.txt  \\\n",
       "this               0.092503    0.092503     0.092503    0.092503   \n",
       "is                 0.146815    0.146815     0.146815    0.146815   \n",
       "shareware          4.131159    0.000000     0.000000    0.000000   \n",
       "trial              2.521721    0.000000     0.000000    0.000000   \n",
       "project            2.684240    0.000000     0.000000    0.000000   \n",
       "...                     ...         ...          ...         ...   \n",
       "priveledge         0.000000    0.000000     0.000000    0.000000   \n",
       "freshest           0.000000    0.000000     0.000000    0.000000   \n",
       "wellmaintained     0.000000    0.000000     0.000000    0.000000   \n",
       "sentenial          0.000000    0.000000     0.000000    0.000000   \n",
       "caryns             0.000000    0.000000     0.000000    0.000000   \n",
       "\n",
       "                3student.txt  3wishes.txt  4moons.txt  5orange.txt  \\\n",
       "this                0.092503     0.092503    0.092503     0.092503   \n",
       "is                  0.146815     0.146815    0.146815     0.146815   \n",
       "shareware           0.000000     0.000000    0.000000     0.000000   \n",
       "trial               0.000000     0.000000    0.000000     0.000000   \n",
       "project             0.000000     0.000000    0.000000     0.000000   \n",
       "...                      ...          ...         ...          ...   \n",
       "priveledge          0.000000     0.000000    0.000000     0.000000   \n",
       "freshest            0.000000     0.000000    0.000000     0.000000   \n",
       "wellmaintained      0.000000     0.000000    0.000000     0.000000   \n",
       "sentenial           0.000000     0.000000    0.000000     0.000000   \n",
       "caryns              0.000000     0.000000    0.000000     0.000000   \n",
       "\n",
       "                6ablemen.txt  6napolen.txt  ...  vgilante.txt  weaver.txt  \\\n",
       "this                0.092503      0.092503  ...      0.092503    0.092503   \n",
       "is                  0.000000      0.146815  ...      0.146815    0.146815   \n",
       "shareware           0.000000      0.000000  ...      0.000000    0.000000   \n",
       "trial               0.000000      0.000000  ...      2.521721    0.000000   \n",
       "project             0.000000      0.000000  ...      2.684240    0.000000   \n",
       "...                      ...           ...  ...           ...         ...   \n",
       "priveledge          0.000000      0.000000  ...      0.000000    0.000000   \n",
       "freshest            0.000000      0.000000  ...      0.000000    0.000000   \n",
       "wellmaintained      0.000000      0.000000  ...      0.000000    0.000000   \n",
       "sentenial           0.000000      0.000000  ...      0.000000    0.000000   \n",
       "caryns              0.000000      0.000000  ...      0.000000    0.000000   \n",
       "\n",
       "                weeprncs.txt  wisteria.txt  wlgirl.txt  wolf7kid.txt  \\\n",
       "this                0.092503      0.092503    0.092503      0.092503   \n",
       "is                  0.000000      0.146815    0.146815      0.000000   \n",
       "shareware           0.000000      0.000000    0.000000      0.000000   \n",
       "trial               0.000000      0.000000    0.000000      0.000000   \n",
       "project             0.000000      0.000000    0.000000      0.000000   \n",
       "...                      ...           ...         ...           ...   \n",
       "priveledge          0.000000      0.000000    0.000000      0.000000   \n",
       "freshest            0.000000      0.000000    0.000000      0.000000   \n",
       "wellmaintained      0.000000      0.000000    0.000000      0.000000   \n",
       "sentenial           0.000000      0.000000    0.000000      0.000000   \n",
       "caryns              0.000000      0.000000    0.000000      0.000000   \n",
       "\n",
       "                wolfcran.txt  wolflamb.txt  yukon.txt  zombies.txt  \n",
       "this                     0.0      0.092503   0.092503     0.092503  \n",
       "is                       0.0      0.146815   0.146815     0.146815  \n",
       "shareware                0.0      0.000000   0.000000     0.000000  \n",
       "trial                    0.0      0.000000   0.000000     0.000000  \n",
       "project                  0.0      0.000000   0.000000     0.000000  \n",
       "...                      ...           ...        ...          ...  \n",
       "priveledge               0.0      0.000000   0.000000     4.824306  \n",
       "freshest                 0.0      0.000000   0.000000     4.824306  \n",
       "wellmaintained           0.0      0.000000   0.000000     4.824306  \n",
       "sentenial                0.0      0.000000   0.000000     4.824306  \n",
       "caryns                   0.0      0.000000   0.000000     4.824306  \n",
       "\n",
       "[44108 rows x 249 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82557998, 0.15447263, 0.84516124, ..., 0.66463256, 0.09015889,\n",
       "       0.36053722])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = pd.Series()\n",
    "\n",
    "for doc, arr in matrix.items():\n",
    "    rank[doc] = np.dot(query_vector,arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gulliver.txt    13838.203396\n",
       "vgilante.txt    10712.236161\n",
       "radar_ra.txt    10143.814668\n",
       "hitch2.txt       9649.153954\n",
       "hitch3.txt       9551.116050\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
